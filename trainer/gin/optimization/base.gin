
# -*-Python-*-
import ddsp
import ddsp.training

# Globals for easier configuration with --gin_param
learning_rate = 3e-4
batch_size = 16
early_stop_loss_value = 4.5

train_util.train.batch_size = %batch_size
train_util.train.num_steps = 256
train_util.train.steps_per_summary = 64
train_util.train.steps_per_save = 64
train_util.train.early_stop_loss_value = %early_stop_loss_value

Trainer.learning_rate = %learning_rate
Trainer.lr_decay_steps = 10000
Trainer.lr_decay_rate = 0.98
Trainer.grad_clip_norm = 3.0
Trainer.checkpoints_to_keep = 10